{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course Introduction: Practical AI - Fall 2024\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Hello and welcome to Practical AI!\n",
    "\n",
    "This is a one semester advanced course on the practical aspects of designing, developing, and deploying artificial intelligence (AI) applications. The course material will cover and apply to a broad span of AI methods and a similarly broad span of applications, with in-depth focus on deep learning enabled perception methods, i.e., methods for using deep neural networks for detecting, classifying, and keeping track of patterns in data. The theory of some common deep learning architectures will be briefly reviewed, but as we will see throughout the semester, knowing the theory of a specific AI technique or architecture in isolation is not enough to enable us to design, develop, and deploy robust systems which perform reliably on constantly changing real-world data.\n",
    "\n",
    "See the course syllabus for information on the course outline, expectations, schedule, and topics. Here we will review some motivating examples which show why it is important to consider the practical aspects of implementing an AI system. Some of these examples may be familiar and some of them may be new. By the end of this course, however, we will have built the concepts to understand all of these examples in depth, and implement mitigations for many of them in the practical AI systems we will design. We will start with a discussion around the relevance of AI to our modern life. We will then look at a few key definitions of technical terms related to AI before moving on to discuss some example challenges that AI systems need to address to perform well in the real world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-World Context and Motivation\n",
    "\n",
    "Due to the relatively recent prevalence of AI systems, we often hear of the significant impacts (both positive and negative) that the technology will have on our daily lives, and on broader societies. Investors see the prevalence of AI this decade as similar to the \"dot-com Bubble\" in the '90s, when internet use became widespread. Industry-leading technology companies, including Meta, Alphabet, Apple, Amazon, Netflix, and many others are competing with newer entrants, such as OpenAI, for leadership in this new space. Products we have been familiar with for decades, such as cell-phones and cars, are being augmented with AI capabilities, and AI is increasingly being used in critical industries, such as medicine and defense. For familiar products, like cell-phones, we already see offerings without useful AI augmentation as behind the curve. For example, if introduced in the early 2000s, a chat service like Apple's Siri would have seemed revolutionary compared to legacy chatbot attempts like America Online's (AOL's) SmarterChild. Today, however, most do not remember SmarterChild and Apple's Siri was lamented by MorningStar as lagging so far behind competing AI technology (e.g., Amazon Alexa) that it was cited as a reason maintain a bear position on Apple stock!\n",
    "\n",
    "For products that are familiar to specialists in critical industries like defense and medicine, but perhaps unfamiliar to those outside these fields, the race to reap the benefits of AI technology is equally competitive, often with critical stakes for individuals, groups, and societies. AI has been employed in the Russia-Ukraine and Israel-Palestine conflicts. Global world power are competing for leadership in the technology, often with different underlying goals, raising serious ethical considerations with different nations around the world adopting different policies on AI in military applications. In medicine, AI is achieving superhuman performance on many narrow tasks such as cancer screening and disease diagnosis. However, the tendency for prominent AI techniques to produce the correct answers for the wrong reasons still presents significant risks. The use of AI in self-driving vehicles has brought many philosophical questions once confined to the classroom (such as the famous trolley problem in ethics) to the heart of engineering design discussions for the specialists who design these systems. Issues with all-weather sensor reliability, once a goal more important for military applications than civilian applications, now make headlines as self-driving cars must accurately discriminate people, objects, and other vehicles, despite challenging weather conditions such as rain, fog, and changes in lighting.\n",
    "\n",
    "As with any new technology, the utility of each AI capability introduced to the world, either through an augmentation to an existing product or as a new product entirely, will come at the plateau of a technology hype-cycle, i.e., the \"plateau of productivity.\" Similarly, as with other technological advances that impacted critical applications, such as the prevalence of software in modern devices (even those we do not typically think of as computers), the invention of new modes of travel (e.g., sea and air travel), and even the use of electricity itself, the maturation of AI from a field of experimental study to a mature practice suitable for real-world deployment will require AI practitioners adopt and implement a rich repertoire of safeguards. Practitioners will need to adopt these safeguards both proactively, to prevent forseen incidents involving AI technology, and reactively, to ensure lessons learned from previous implementations are not forgotten.\n",
    "\n",
    "The importance of this practice, and the responsibility that we have as a community of practitioners to help mature the AI field to the status of an established discipline can be emphasized by drawing analogies to examples just cited of similar progress in other impactful fields. For a description of the prevalence of software in our modern world and the important responsibility that all software craftspeople have to ensure that code runs smoothly through the adoption of hard-won principles and practices, see Robert C. Martin's Clean Code lectures and book. For an example of the importance of standards to similarly critical fields, look to the codes of practice that govern aviation manufacturing, air and sea navigation, and electrical work (i.e., the National Electrical Code). For a growing list of incidents in which AI systems deployed to the real world have caused harms to individuals, groups, and societies, we will continually reference the AI Incident Database, which maintains a living list of such instances. The incidents documented range from annoyances for users of systems, to harmful injustices, and tragic outcomes with injuries and lives lost from those who were not using an AI system directly. It is not necessary to read or know all these references to proceed with this course (except for those interested!) but it is necessary to realize the role that we all play as AI practitioners in adopting similarly responsible practices as the AI field matures, to prevent reoccurrences of past AI incidents and proactively prevent future AI incidents.\n",
    "\n",
    "Let's take some time to look around the [AI Incident Database](https://incidentdatabase.ai/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Definitions and Terminology\n",
    "\n",
    "Before we discuss some challenges to the implementation of AI systems that perform well in the real world and provide a preview to how this course will help us address these challenges, we need to define some key terms in AI and related fields.\n",
    "\n",
    "A study guide on these terms will be provided.\n",
    "\n",
    "### Preliminaries\n",
    "\n",
    "* Perception\n",
    "* Action\n",
    "* Observe-Orient-Decide-Act (OODA) Loops\n",
    "* Systems\n",
    "* AI Systems and AI Components\n",
    "* Whitebox, Blackbox, and Greybox Systems and Methods\n",
    "* Linear and Nonlinear Functions and Systems\n",
    "* Non-determinism\n",
    "\n",
    "### Artificial Intelligence (AI)\n",
    "\n",
    "* Artificial Intelligence\n",
    "* Machine Learning\n",
    "* Deep Learning\n",
    "* Models\n",
    "\n",
    "### Types of Learning\n",
    "* Supervised Learning\n",
    "* Unsupervised Learning\n",
    "* Reinforcement Learning\n",
    "* Remember that self-supervised learning is supervised learning!\n",
    "\n",
    "### Types of AI Tasks\n",
    "\n",
    "* Detection\n",
    "* Classification\n",
    "* Semi-supervised and Weakly-Supervised Learning\n",
    "* Few-shot and Zero-shot Learning\n",
    "\n",
    "### Machine Learning Operations (MLOps)\n",
    "\n",
    "* Related Term: Development and Security Operations (DevSecOps)\n",
    "* Data Augmentation\n",
    "* Data Transformation\n",
    "* Model Selection\n",
    "* Continual Learning / Life-long Learning\n",
    "* Catastrophic Forgetting\n",
    "* Explainable AI (XAI)\n",
    "* Confounding Attributes\n",
    "* Adversarial AI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "Let's talk through some basic examples showing how AI systems can appear to perform well in controlled experiments but exhibit poor performance in the real world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Trusting Correlation\n",
    "\n",
    "Sometimes two features appear to be uncorrelated but are really strongly related. Other times, two features appear to be highly correlated but are really unrelated.\n",
    "\n",
    "When might this be a problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Poor Software Hygiene\n",
    "\n",
    "Sometimes sneaky bugs in our code lead us to believe that our system will perform much better than it really does.\n",
    "\n",
    "Good software practices can mitigate this risk and will be a theme in this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Data Drift\n",
    "\n",
    "Real world data is constantly changing. Often models perform well initially, but the data distribution changes over time, leading to poor performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4: Noisy Data\n",
    "\n",
    "Noise in the data is often one of the biggest factors that can hurt model performance in the real world. Sometimes models can be trained on noisy data to increase robustness. Other times, noise can be detected and model decisions can be thrown out if unreliable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 5: The Veterinary Dentists Rule\n",
    "\n",
    "Often in machine learning there is temptation to apply models to specialized tasks in specialized fields without consideration for problems that will affect model performance that might only be obvious to those with a specialty in those fields! Such problems may have been obvious to experts in the specialized field of application but likely would go unnoticed by engineers with a typical machine learning background.\n",
    "\n",
    "To ensure ML models perform well on real-world tasks, we need to leverage expertise in ML *and* in the domain of application.\n",
    "\n",
    "In this class, we will call this the Veterinary Dentists rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 6: Forgetting Necessary Pre-processing\n",
    "\n",
    "Even on simple tasks, ML fits are only valid on the domain in which the model was trained. Even advanced ML techniques have difficulty with extrapolation (vs. interpolation, where ML excels) outside their training distributions.\n",
    "\n",
    "This can even be a problem when applying ML to simple tasks, like fitting mathematical functions. We might be tempted to then conclude that using machine learning tools to approximate mathematical functions is a poor use case, however, there is a rich and useful literature around using machine learning to do just that. These methods are especially useful for expediting the solution of mathematical functions by training a neural network to approximately predict their solution on a GPU. We need to pick our use cases carefully, and weight the risks and benefits of each option when deciding how to approximate a function and whether we should employ machine learning to do so.\n",
    "\n",
    "We will learn to employ Ocam's razor and other model selection techniques when selecting ML models for a given task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 7: Learning the Right Result for the Wrong Reason\n",
    "\n",
    "One of the most challenging ML pitfalls can be when models learn the correct result fo the wrong reason. For example, an image classifier might learn to classify cars from trucks well. But what if all the images of cars were taken at sunset. Did the classifier learn what a car looked like or learn what the color of the background was?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 8: Adversarial Attack\n",
    "\n",
    "One of the most important considerations for robust ML is robustness to an emerging array of adversarial attack techniques, which seek to exploit the way ML models work to deceive them in ways that in most cases would not fool humans. We will practice attacks and defenses against attacks in this class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lessons Learned\n",
    "\n",
    "As we will continue to see throughout the course, even performing seemingly simple tasks with AI tools can come with risks, and for some tasks AI is not always be the right tool for the job. For more difficult tasks, some challenges to reliable AI deployment in the real world are just beginning to be addressed as the AI field matures. The fields of AI explainability, machine learning operations, and adversarial AI will continue to evolve as the AI field evolves, much in the same way the fields of software engineering, cybersecurity, and other disciplines evolved best practices as they matured over decades. This course will present a snapshot of some of the most important current best practices evolving in the AI field. By the end of this course, students will be able to spot common issues and risks in existing AI systems, and grasp the basic principles needed to design a new AI system from the ground up."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
